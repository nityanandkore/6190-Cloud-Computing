# What problems does edge-based machine learning solve?

Due to the limited memory and computation resources of edge devices, training large amounts of data on the devices is not feasible most of the times. The deep learning models are trained in powerful on-premises or cloud server instances and then deployed on the edge devices.
Developers can use several methods to tackle this issue: designing power-efficient ML algorithms, developing better and more specialized hardware, and inventing new distributed-learning algorithms where all IoT devices communicate and share data.
The last approach is limited by the network bandwidth, therefore future 5G networks, which provide ultra-reliable, low-latency communication services, will help immensely in the area of edge computing.

In addition, edge-based ML has been shown to enhance the privacy and security of the data sets that the edge devices capture, since they can be programmed to discard the sensitive data fields. Overall system response times are improved due to the edge devices processing the data, enriching them (by adding metadata) and then sending them to the backend systems.


# What are the ML frameworks most widely used with edge inference?

The table below describes some of the most popular ML frameworks that run on edge devices. Most of these frameworks provide pre-trained models for speech recognition, object detection, natural language processing (NLP), and image recognition and classification, among others. They also give the option to the data scientist to leverage transfer learning or start from scratch and develop a custom ML model.


# Post a screenshot of a lab where you had difficulty with a concept or learned something.** **
